{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate a dataset of voxels (on-the-fly) for training deep learning models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('../')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from docktgrid import VoxelDataset, VoxelGrid\n",
                "from docktgrid.view import BasicView, VolumeView\n",
                "from docktgrid.transforms import RandomRotation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(21, 24, 24, 24)"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# create a voxelgrid object\n",
                "voxel = VoxelGrid(\n",
                "    views=[VolumeView(), BasicView()],  # you can add multiple views; they are executed in order\n",
                "    vox_size=1.0,                       # size of the voxel (in Angstrom)\n",
                "    box_dims=[24.0, 24.0, 24.0],        # dimensions of the box (in Angstrom)\n",
                ")\n",
                "voxel.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# create a dataset object\n",
                "pdbs = [\"1xap\", \"2weg\", \"4bb9\", \"4qsu\", \"6std\"]\n",
                "data = VoxelDataset(\n",
                "    protein_files=[f\"{pdb}_protein.pdb\" for pdb in pdbs],\n",
                "    ligand_files=[f\"{pdb}_ligand.pdb\" for pdb in pdbs],\n",
                "    labels=range(len(pdbs)),\n",
                "    voxel=voxel,\n",
                "    transform=[RandomRotation()],         # use None if you don't want to apply any transformation\n",
                "    root_dir=\"../tests/data/dataset\",\n",
                ")\n",
                "\n",
                "len(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([21, 24, 24, 24]) tensor(0.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(1.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(2.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(3.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(4.)\n"
                    ]
                }
            ],
            "source": [
                "# iterate over the dataset\n",
                "def iterate():\n",
                "    for x, y in data:\n",
                "        print(x.shape, y)\n",
                "\n",
                "iterate()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Loading files beforehand (optional)\n",
                "\n",
                "To avoid reading the molecular files every time, we can use the `scripts.preprocess_dataset` script to searialize molecular objects for faster loading. For more information on how to use the script, run `python -m scripts.preprocess_dataset --help`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pickle\n",
                "\n",
                "# preprocess the dataset\n",
                "# python -m docktgrid.scripts.preprocess_dataset --pattern '*.pdb' --dir tests/data/dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['1xap_protein.pdb.pkl', '2weg_protein.pdb.pkl', '4bb9_protein.pdb.pkl', '4qsu_protein.pdb.pkl', '6std_protein.pdb.pkl']\n",
                        "['1xap_ligand.pdb.pkl', '2weg_ligand.pdb.pkl', '4bb9_ligand.pdb.pkl', '4qsu_ligand.pdb.pkl', '6std_ligand.pdb.pkl']\n"
                    ]
                }
            ],
            "source": [
                "files = os.listdir(\"../data/processed/\")\n",
                "protein_files = sorted([f for f in files if \"protein\" in f])\n",
                "ligand_files = sorted([f for f in files if \"ligand\" in f])\n",
                "\n",
                "print(protein_files)\n",
                "print(ligand_files)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Load the data into memory first:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "protein_mols = [pickle.load(open(f\"../data/processed/{f}\", \"rb\")) for f in protein_files]\n",
                "ligand_mols = [pickle.load(open(f\"../data/processed/{f}\", \"rb\")) for f in ligand_files]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also exclude protein atoms that are outside the bounding box of the voxel grid (optional):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "from docktgrid.molparser import extract_binding_pocket\n",
                "import numpy as np\n",
                "\n",
                "for i, ptn in enumerate(protein_mols):\n",
                "    radius = np.ceil(np.sqrt(3) * max(voxel.shape[1:]) / 2)  # radius of the sphere that contains the voxel grid\n",
                "    inside_atoms_idx = extract_binding_pocket(ptn.coords, ligand_mols[i].coords.mean(dim=1), radius)\n",
                "    \n",
                "    # keep only the atoms inside the binding pocket, rewrite the MolecularData attributes\n",
                "    ptn.coords = ptn.coords[:, inside_atoms_idx]\n",
                "    ptn.element_symbols = ptn.element_symbols[inside_atoms_idx]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = VoxelDataset(\n",
                "    protein_files=protein_mols,\n",
                "    ligand_files=ligand_mols,\n",
                "    labels=range(len(protein_files)),\n",
                "    voxel=voxel,\n",
                "    transform=[RandomRotation()],  # use None if you don't want to apply any transformation\n",
                "    root_dir=\"../data/processed/\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Iterating over the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.Size([21, 24, 24, 24]) tensor(0.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(1.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(2.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(3.)\n",
                        "torch.Size([21, 24, 24, 24]) tensor(4.)\n"
                    ]
                }
            ],
            "source": [
                "# iterate over the dataset\n",
                "for x, y in data:\n",
                "    print(x.shape, y)\n",
                "    # your training code here..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
